## 基础技术

### 1.Hive分区表删除分区的命令是什么？分区表新增字段注意事项是什么？

>alter table table_name drop partition (dt=)
>
>分区表新增字段命令后要加cascade关键字，直接对表的元数据进行刷新，避免对更新过的表格查询时出现新增字段为空值或null的情况。

### 2.hive-sql优化工作中实际做过哪些？结合实际场景讲述？

> hive-sql的优化分为主要分为三个方面：数据的选择过滤方面、表之间的join连接、数据的聚合方面
>
> 数据的选择过滤方面分为三种，分区裁剪、列裁剪、谓词下推
>
> - 分区裁剪：主表的过滤条件放在where里才能生效，从表的过滤条件放在on里才能生效。本质是在路径上对数据进行划分，是真正减少数据的读取量的
> - 列裁剪：本身不减少读取的数据量，减少的是mapper处理的数据量
> - 谓词下推：尽可能早过滤数据
>
> 数据的汇总聚合方面
>
> - 对order by的优化，优化为distribute by+sort by的形式，比如在求topN类问题的时候，能避免但reduce对全局进行排序的情况。
> - 将count（distinct）通过group by进行优化，将全局去重优化为分组去重，在性能上进行优化
>
> 表间join连接方面
>
> - sql出现oom或gc问题时，一般是通过开启mapjoin进行优化，还能通过参数来调整map处理的数据量和核数。
> - 在大表join大表时，同过SMBjoin进行优化，不过这要要求两表的分桶数是倍数关系
> - sql中出现union或有并列子查询时可以开启并行执行的参数

### 3.一段很长的SQL代码，如果出现数据倾斜，如何快速定位那段代码出现了问题？

> 通过查看查看日志，yarn提供web UI，查看具体任务，web UI提供该任务所属的stage，在查看具体的执行日志，应该就能定位出具体那段代码出现问题

### 4.用户登录表login_table，记录了用户的ID,求用户最长的连续登录天数以及起始日期。用hive-sql，不能用UDAF或MR实现。

```sql

select
    b.user_id,
    min(login_date) as start_date
    count(1) as login_attempts
from
    (
    -- 序号和日期相减
    select
        user_id,
        login_date,
        date_sub(login_date,rank) as new_date
    from
        (
        -- 开窗函数对按用户分组，并按日期顺序排序
        select 
            user_id,
            login_date,
            row_number() over(partition by user_id order by login_date) as rank
        from login_table
        ) a
    ) b
group by b.user_id,b.new_date
having max(login_attempts)    
```



### 5.t_bill表大约100亿条记录数，t_item表约1000w条记录数，由于t_bill的item并不均匀，导致了长尾问题，改写一下sql优化执行效率。（不能简单mapjoin，会导致内存溢出）

> 思路：直接将长尾任务涉及的数据提取出来单独处理，处理完成再union回去，将一个任务拆分成两个任务去并行处理。出现OOM问题那就之间调整单个map的处理量和核数。

```sql
```



### 6.工作中有没有遇到锁表的情况，什么情况下出现？你是如何处理的？

> 锁表的情况有遇到过， 出现在多人同时访问读取或操作同一表格的情况下。
>
> 同时访问读取的话，涉及到的锁是共享锁，共享锁是可以并发执行的，这种情况下不需要处理，是可以同时访问的
>
> 要对统一表格进行操作会涉及到互斥锁，互斥锁是不能并发执行的。处理方法：如果触发互斥锁，需要等先触发互斥锁的用户修改完成后，再对锁进行释放，其他用户才能再进行读取和修改

### 7.小文件你工作中一般在那种情况下出现，以及你是如何治理小文件的？

> 较为常见的一些配置类的小文件。分区导致的小文件过多，比如表的过度分区、动态分区等都可能导致小文件过多。
>
> 数据源本身就含有大量小文件。
>
> map-only任务过多的map，map-reduce任务过多的reduce也都可能导致小文件过多。
>
> 先处理增量小文件，把产生小文件的阀门关闭，不能一边治理着一边还在产生新的小文件，这样治理就没有意义了
>
> 接着处理存量小文件，包括小文件的合并，无用小文件的删除。开启小文件合并的四个参数，以及控制split相关的参数。

### 8.spark和hive有什么区别？spark为什么比MapReduce要快？

> spark本身就是处理大数据的引擎框架，hive是依托HDFS存储，提供元数据管理和hivesql的解析工具，将sql任务解析为MapReduce任务去执行。spark能做批处理、流处理和交互式查询，hive主要做批处理。
>
> spark比MR快的原因：
>
> - spark采用的DAG机制，只有action算子才能触发job执行，且只有最后一个reduce才进行数据落盘，得益于spark支持将计算的中间数据落到内存中去计算。
> - 从shuffle的角度可以说一个spark任务可以是多个mr任务，但这不是spark更快的原因，本身shuffle次数是由数据要重组的次数决定的。本质是减少了磁盘的IO
> - spark在并行执行上的优化。hive是进程上的并行执行，map task和reduce task都是进程级别的，是jvm进程，开启和关闭都是需要耗费时间的。spark是在线程上的并行执行，当线程执行完一个任务后还能进行复用，能减少资源申请和线程启动关闭task的时间。

### 9.spark工作中用过吗？如何使用的？spark优化做过哪些？（或者用过哪些参数优化）

> 用过，主要是写spark-sql

### 10.任务失败了你是如何排查的？从哪些角度排查？

> 一般都是查看日志，查看任务失败的具体原因是什么。
>
> - 任务中涉及的表、字段是否存在，结构是否符合预期
> - 资源或网络相关问题
> - 硬件问题导致任务失败
> - 可以通过查询计划尝试进行优化

## 项目综合

### 1.你们公司数据质量如何保障？从哪些角度去做的？如何做的？谈谈你对大数据质量的了解？

> 我们公司有专门的dqc平台去做数据质量保障。
>
> 一般是从数据的完整性、准确性、一致性、及时性四个方面去做。完整性，比如在数据的增量拉取上，往日每天大概有10w条左右的数据，某天的数据就只有几千条，这就可能在数据完整性上出现了问题。准确性体现在核心字段是否存在，是否存在空值。数据的一致性体现在从多个业务系统提取数据，字段表示、含义上是否相同，比如在金额单位上，使用美元还是人民币，要在金额的单位上有一致性。及时性主要是体现在任务的产出的及时性。

### 2.数仓的缓慢变化维是什么？怎么处理？为什么这么处理？（结合熟悉的项目业务讲）

> 缓慢变化维是相对其他维度变化较慢的维度字段。
>
> 可以采用直接重写维度、增加维度列、增加维度行和使用拉链表等形式处理
>
> 比如手机号所属省份字段变化，一般是采用拉链表的形式处理，相比其他方法它能通过时间字段来区分哪些是历史维度、哪个是新增维度，同时还能完整的记录维度的变化

### 3.数仓你们制定了哪些数仓规范，分别说一下？

> 数仓的层级规范：比如避免引用穿透、避免逆向引用、避免同层依赖等
>
> 模型命名、字段命名规范，能避免在模型、字段上产生一致性问题，避免冗余、对集群造成不必要的压力
>
> 需求的开发流程规范，代码的管理规范，禁止使用insert into语句，禁止一个任务更新多个目标表等
>
> 任务部署调度规范，比如ETL脚本名称必须与目标表相同等,

### 4.维度建模是什么？为啥要用维度建模？（结合业务去讲）

> 维度建模是建设数据仓库的一套方法论，是数据仓库建设的理论工具。数仓建设较为常见的建设理论包括范式建模和维度建模。
>
> 维度建模理论本身就是大量的实践经验总结出来的一套理论，维度建模为模型建设提供了清晰的实施步骤，较为核心的步骤为：
>
> - 选择业务过程：以电商项目的订单流程环节为例。
> - 声明粒度：在确定了模型建设数据范围后，要明确该范围内最小单位的数据集所代表的含义。此处每行数据就是指每笔订单
> - 确认维度：也就是确认对数据的分析角度，根据具体的需求获取。比如下订单的时间维度，地域维度
> - 确认事实：事实一般是具有度量性质的数值类型的数据。比如订单金额

### 5.在数仓建模中，分层是很重要的一个概念。你认为怎样的分层模式是比较好的，为什么？以及分层的边界和准则是什么？

> 数仓分层模式应该根据具体的情况进行选择，要能满足业务需求，还要在模型的可扩展性、数据一致性、数据质量保障和数据维护等方面进行考虑。较为常见的是阿里的基于onedata的数仓建设方法论。
>
> - ods层：一般是对各业务系统数据进行提取，不对数据进行清洗转换。起到数仓和业务系统隔离的效果，避免重复数据数据提取对业务系统造成的压力
> - dim层：数仓的维度层，相关业务事实的分析维度。
> - dwd层：对ods层的数据进行清洗加工。在确定业务过程后，构建最细粒度的明细事实表。可适当做宽表化处理，冗余一下重要字段，尽量减少数据处理时的表关联。
> - dws层：对dwd层的数据按照一定的维度进行聚合处理。
> - app层：面向具体的需求，为报表、数据分析或数据挖掘等提供数据支持。

### 6.你们公司数据源是怎样的？数据采集做过吗？了解数据采集的增量更新，全量更新吗？什么场景使用？

> 增量更新一般在大数据量是使用，避免较大的存储开销。同时数据变更相对较小时使用增量更新。
>
> 全量更新一般在小数据量时使用，对集群的等性能方面不会造成太大压力，同时数据的变更比较频繁时使用。

### 7.印象最深的项目？为什么？你在其中的亮点和优势？

> 互联网金额用户画像的项目
>
> 用户画像是我较早接触到项目，印象较深是因为它能用用户的基本属性+行为数据，通过一定的算法或数据处理手段能在互联网上对人进行分类，虽然分类还不够细，更没法做到唯一性（主要是没必要，成本太高），但能满足我对未来构建数字个体的畅想。
>
> 主要优势是对复杂模型的处理，比如RMF模型等

### 8.数仓架构与分层，这样分层的好处？（结合项目具体讲）

> - 能理清数据的血缘关系：对数据的上下游的表做清晰地定位，出了问题可以根据血缘关系快速定位
> - 梳理数据结构，数仓各层都有它们各自的特点，能对数据的架构有清晰的认知，使用数据时更好理解和定位，模型有具体的命名规范。
> - 降本增效，减少重复开发:通过数仓对数据的逐层处理，面向业务来满足数据的高可用，避免一些重复数据清洗、重复计算的操作，能很好的提高开发效率
> - 单独建立数仓能屏蔽原始数据的影响，因为数据是单独抽取到数仓的，数据处理是层层递进的，避免原始数据的变更对数据稳定性的影响。

### 9.你们公司数仓开发有多少人？你们公司集群多大？有多少数据？熟悉哪些调度系统？

### 10.了解HBASE，presto,clickhouse，kafka,doris,starrocks等组件吗？知道各自的应用场景吗？

> habse是运行在HDFS上的分布式存储系统，能够在数据库上实时运行，适合进行数据的实时查询。
>
> presto是采用MPP架构的查询引擎，可接入多数据源，支持跨数据源的快速交互式查询。

### 11.结合熟悉的项目讲讲，你在其中的工作职责？

> 以用户画像项目的工作为例，主要是根据标签管理平台对标签创建、变更、删除做管理，当然还包括一些统计类、规则类的标签的开发，脚本的开发及处理。还有任务调度配置和维护。

### 12.数据治理做过吗？谈谈你对数据治理的理解？以及你做过哪些相关的数据治理？

> 做过，数据治理就是对数据进行管理的概念，保障数据在整个生命周期内发挥它最大的价值。并通过数据治理尽可能的避免在数仓开发建设时可能遇到得问题，尽可能去降低数据管理的风险。最主要的还是降本增效。
>
> 包括表模型名称、字段命名的治理， 表存储格式的治理。主数据的小文件的治理等。  

